{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:08:21.011588Z",
     "iopub.status.busy": "2023-11-13T11:08:21.011080Z",
     "iopub.status.idle": "2023-11-13T11:08:28.938989Z",
     "shell.execute_reply": "2023-11-13T11:08:28.937544Z",
     "shell.execute_reply.started": "2023-11-13T11:08:21.011497Z"
    },
    "id": "KN35l9ZJ3aTh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import datetime as dt\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:08:59.078611Z",
     "iopub.status.busy": "2023-11-13T11:08:59.078036Z",
     "iopub.status.idle": "2023-11-13T11:08:59.083654Z",
     "shell.execute_reply": "2023-11-13T11:08:59.082737Z",
     "shell.execute_reply.started": "2023-11-13T11:08:59.078583Z"
    },
    "id": "1arHoOHI3aTr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VIDEO_FRAME_HEIGHT = 64\n",
    "VIDEO_FRAME_WIDTH = 64\n",
    "import os \n",
    "FRAMES_IN_SEQUENCE = 16\n",
    " \n",
    "DATASET_DIRECTORY = \"./Dataset/Real Life Violence Dataset\"\n",
    "import os\n",
    "current_directory = os.path.exists(DATASET_DIRECTORY)\n",
    "print(f\"Current Working Directory: {current_directory}\")\n",
    "CLASS_LABELS = [\"NonViolence\", \"Violence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:09:03.558522Z",
     "iopub.status.busy": "2023-11-13T11:09:03.558095Z",
     "iopub.status.idle": "2023-11-13T11:09:03.568057Z",
     "shell.execute_reply": "2023-11-13T11:09:03.566705Z",
     "shell.execute_reply.started": "2023-11-13T11:09:03.558491Z"
    },
    "id": "-yB8ePeC3aTs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path, sequence_length=FRAMES_IN_SEQUENCE, image_height=VIDEO_FRAME_HEIGHT, image_width=VIDEO_FRAME_WIDTH):\n",
    "    \"\"\"\n",
    "    Extracts and processes frames from a video file.\n",
    "    \"\"\"\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the total number of frames in the video.\n",
    "    total_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the interval at which to skip frames.\n",
    "    skip_frames_window = max(int(total_frames / sequence_length), 1)\n",
    "    \n",
    "    # Iterate through the video frames.\n",
    "    for frame_index in range(sequence_length):\n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_index * skip_frames_window)\n",
    "        \n",
    "        # Read the frame.\n",
    "        success, frame = video_reader.read()\n",
    "        \n",
    "        # Check if the frame was read successfully. If not, break the loop.\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Resize the frame to the required height and width.\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        \n",
    "        # Normalize the resized frame pixel values.\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        \n",
    "        # Append the normalized frame to the frames list.\n",
    "        frames_list.append(normalized_frame)\n",
    "        \n",
    "    video_reader.release()\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames(f\"{DATASET_DIRECTORY}/NonViolence/NV_1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:09:04.310289Z",
     "iopub.status.busy": "2023-11-13T11:09:04.309897Z",
     "iopub.status.idle": "2023-11-13T11:09:04.318697Z",
     "shell.execute_reply": "2023-11-13T11:09:04.317571Z",
     "shell.execute_reply.started": "2023-11-13T11:09:04.310263Z"
    },
    "id": "vj_AQqju3aTu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    \"\"\"\n",
    "    Creates a dataset of features (frames) and labels from video files.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "\n",
    "    for class_index, class_name in enumerate(CLASS_LABELS):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files in the class directory.\n",
    "        class_dir = os.path.join(DATASET_DIRECTORY, class_name)\n",
    "        files_list = os.listdir(class_dir)\n",
    "        \n",
    "        for file_name in files_list:\n",
    "            video_file_path = os.path.join(class_dir, file_name)\n",
    "            \n",
    "            # Extract frames from the video.\n",
    "            frames = extract_frames(video_file_path)\n",
    "            \n",
    "            # Ensure the video has the required number of frames (FRAMES_IN_SEQUENCE).\n",
    "            if len(frames) == FRAMES_IN_SEQUENCE:\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return features, labels, video_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:09:04.980262Z",
     "iopub.status.busy": "2023-11-13T11:09:04.978950Z",
     "iopub.status.idle": "2023-11-13T11:27:31.802874Z",
     "shell.execute_reply": "2023-11-13T11:27:31.800840Z",
     "shell.execute_reply.started": "2023-11-13T11:09:04.980201Z"
    },
    "id": "rgpokUY83aTv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the dataset.\n",
    "features, labels, video_files_paths = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:27:31.806905Z",
     "iopub.status.busy": "2023-11-13T11:27:31.805493Z",
     "iopub.status.idle": "2023-11-13T11:27:33.938609Z",
     "shell.execute_reply": "2023-11-13T11:27:33.937018Z",
     "shell.execute_reply.started": "2023-11-13T11:27:31.806850Z"
    },
    "id": "Hu8NKv4H3aTv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Saving the extracted data\n",
    "\n",
    "np.save(\"features.npy\",features)\n",
    "np.save(\"labels.npy\",labels)\n",
    "np.save(\"video_files_paths.npy\",video_files_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:27:33.942689Z",
     "iopub.status.busy": "2023-11-13T11:27:33.941722Z",
     "iopub.status.idle": "2023-11-13T11:27:34.906445Z",
     "shell.execute_reply": "2023-11-13T11:27:34.904001Z",
     "shell.execute_reply.started": "2023-11-13T11:27:33.942609Z"
    },
    "id": "9KOPtXlH3aTw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = np.load(\"features.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "video_files_paths = np.load(\"video_files_paths.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:48:43.858084Z",
     "iopub.status.busy": "2023-11-13T11:48:43.857039Z",
     "iopub.status.idle": "2023-11-13T11:48:43.876979Z",
     "shell.execute_reply": "2023-11-13T11:48:43.875445Z",
     "shell.execute_reply.started": "2023-11-13T11:48:43.858032Z"
    },
    "id": "SIN6V5GN3aTw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # convert labels into one-hot-encoded vectors\n",
    "# one_hot_encoded_labels = to_categorical(labels)\n",
    "# one_hot_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:48:44.066604Z",
     "iopub.status.busy": "2023-11-13T11:48:44.065979Z",
     "iopub.status.idle": "2023-11-13T11:48:44.873788Z",
     "shell.execute_reply": "2023-11-13T11:48:44.872148Z",
     "shell.execute_reply.started": "2023-11-13T11:48:44.066569Z"
    },
    "id": "P0uFnKvq3aTx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_files_and_labels():\n",
    "    \"\"\"\n",
    "    Gets a list of all video file paths and their corresponding labels.\n",
    "    This does NOT load the video data into memory.\n",
    "    \"\"\"\n",
    "    video_files_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_index, class_name in enumerate(CLASS_LABELS):\n",
    "        print(f'Getting file paths for class: {class_name}')\n",
    "        class_dir = os.path.join(DATASET_DIRECTORY, class_name)\n",
    "        \n",
    "        for file_name in os.listdir(class_dir):\n",
    "            video_file_path = os.path.join(class_dir, file_name)\n",
    "            video_files_paths.append(video_file_path)\n",
    "            labels.append(class_index)\n",
    "            \n",
    "    return video_files_paths, labels\n",
    "\n",
    "# 1. Get the list of all file paths and their corresponding integer labels.\n",
    "all_video_paths, all_labels = get_files_and_labels()\n",
    "\n",
    "# 2. Convert the integer labels to one-hot encoded vectors.\n",
    "one_hot_encoded_labels = to_categorical(all_labels)\n",
    "\n",
    "# 3. Split the file paths and their labels into training and test sets.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    all_video_paths, \n",
    "    one_hot_encoded_labels,\n",
    "    test_size=0.1,  # Using 10% for testing\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total videos for training: {len(features_train)}\")\n",
    "print(f\"Total videos for testing: {len(features_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:46:40.396051Z",
     "iopub.status.busy": "2023-11-13T15:46:40.395581Z",
     "iopub.status.idle": "2023-11-13T15:46:41.620541Z",
     "shell.execute_reply": "2023-11-13T15:46:41.618879Z",
     "shell.execute_reply.started": "2023-11-13T15:46:40.396013Z"
    },
    "id": "Tpo2Q-Uf3aT8",
    "outputId": "fccd8ac7-0787-4b33-cf27-7a303ada1c0e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "mobilenet = MobileNetV2(include_top=False , weights=\"imagenet\")\n",
    "\n",
    "mobilenet.trainable=True\n",
    "for layer in mobilenet.layers[:-100]:\n",
    "  layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:46:42.863783Z",
     "iopub.status.busy": "2023-11-13T15:46:42.863401Z",
     "iopub.status.idle": "2023-11-13T15:46:42.875605Z",
     "shell.execute_reply": "2023-11-13T15:46:42.874267Z",
     "shell.execute_reply.started": "2023-11-13T15:46:42.863756Z"
    },
    "id": "CWtYR7bM3aT9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def construct_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(FRAMES_IN_SEQUENCE, VIDEO_FRAME_HEIGHT, VIDEO_FRAME_WIDTH, 3)))\n",
    "    model.add(TimeDistributed(mobilenet))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    lstm_fw = LSTM(units=32)\n",
    "    lstm_bw = LSTM(units=32, go_backwards=True)\n",
    "    model.add(Bidirectional(lstm_fw, backward_layer=lstm_bw))\n",
    "    dense_units = [256, 128, 64, 32]\n",
    "    for units in dense_units:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Dense(len(CLASS_LABELS), activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the Model\n",
    "\n",
    "my_model = construct_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "\n",
    "class VideoDataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Custom Keras data generator for loading video data on the fly.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_paths, labels, batch_size, sequence_length, image_dims):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.image_height, self.image_width = image_dims\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return math.ceil(len(self.video_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data.\n",
    "        start_index = index * self.batch_size\n",
    "        end_index = (index + 1) * self.batch_size\n",
    "        batch_paths = self.video_paths[start_index:end_index]\n",
    "        batch_labels = self.labels[start_index:end_index]\n",
    "\n",
    "        # Initialize batch data.\n",
    "        batch_features = np.zeros((len(batch_paths), self.sequence_length, self.image_height, self.image_width, 3), dtype=np.float32)\n",
    "\n",
    "        for i, path in enumerate(batch_paths):\n",
    "            # Use the extract_frames function you wrote earlier.\n",
    "            frames = extract_frames(path, self.sequence_length, self.image_height, self.image_width)\n",
    "            if len(frames) == self.sequence_length:\n",
    "                batch_features[i] = frames\n",
    "\n",
    "        return batch_features, np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set the batch size.\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Create instances of your data generator for training and validation.\n",
    "train_generator = VideoDataGenerator(\n",
    "    video_paths=features_train,\n",
    "    labels=labels_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sequence_length=FRAMES_IN_SEQUENCE,\n",
    "    image_dims=(VIDEO_FRAME_HEIGHT, VIDEO_FRAME_WIDTH)\n",
    ")\n",
    "\n",
    "val_generator = VideoDataGenerator(\n",
    "    video_paths=features_test,\n",
    "    labels=labels_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sequence_length=FRAMES_IN_SEQUENCE,\n",
    "    image_dims=(VIDEO_FRAME_HEIGHT, VIDEO_FRAME_WIDTH)\n",
    ")\n",
    "\n",
    "# --- Model Compiling and Callbacks (same as before) ---\n",
    "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001, verbose=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# --- THE CORRECTED MODEL.FIT() CALL ---\n",
    "print(\"Starting model training with the custom data generator...\")\n",
    "MobBiLSTM_model_history = my_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping_callback, reduce_lr]\n",
    ")\n",
    "print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 4\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((features_train, labels_train))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(features_train)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((features_test, labels_test))\n",
    "# val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T15:46:51.987294Z",
     "iopub.status.busy": "2023-11-13T15:46:51.986787Z",
     "iopub.status.idle": "2023-11-13T16:27:34.132693Z",
     "shell.execute_reply": "2023-11-13T16:27:34.130652Z",
     "shell.execute_reply.started": "2023-11-13T15:46:51.987249Z"
    },
    "id": "oA-QWlSV3aT_",
    "outputId": "f1b4723e-1d04-4842-b5c6-29338569f694",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001, verbose=1)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# my_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# # --- THE CORRECTED MODEL.FIT() CALL ---\n",
    "# print(\"Starting model training with tf.data.Dataset...\")\n",
    "# MobBiLSTM_model_history = my_model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=50,\n",
    "#     validation_data=val_dataset,\n",
    "#     callbacks=[early_stopping_callback, reduce_lr]\n",
    "# )\n",
    "# print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T17:05:15.635065Z",
     "iopub.status.busy": "2023-11-13T17:05:15.630328Z",
     "iopub.status.idle": "2023-11-13T17:05:18.703966Z",
     "shell.execute_reply": "2023-11-13T17:05:18.702790Z",
     "shell.execute_reply.started": "2023-11-13T17:05:15.634922Z"
    },
    "id": "6577H1to3aT_",
    "outputId": "dd4650e7-7089-4931-d526-c98440b7210b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_evaluation_history = my_model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T17:21:05.154625Z",
     "iopub.status.busy": "2023-11-13T17:21:05.154195Z",
     "iopub.status.idle": "2023-11-13T17:21:05.576782Z",
     "shell.execute_reply": "2023-11-13T17:21:05.574286Z",
     "shell.execute_reply.started": "2023-11-13T17:21:05.154589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "my_model.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('Model.h5')\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:29:57.819863Z",
     "iopub.status.busy": "2023-11-13T14:29:57.819339Z",
     "iopub.status.idle": "2023-11-13T14:29:57.832781Z",
     "shell.execute_reply": "2023-11-13T14:29:57.831477Z",
     "shell.execute_reply.started": "2023-11-13T14:29:57.819821Z"
    },
    "id": "p4gjtz-73aUE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_video_class(video_file_path, SEQUENCE_LENGTH=16):\n",
    "    try:\n",
    "        video_reader = cv2.VideoCapture(video_file_path)\n",
    "        if not video_reader.isOpened():\n",
    "            print(\"Error: Unable to open video file.\")\n",
    "            return\n",
    "        video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frames_list = []\n",
    "        skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
    "        for frame_counter in range(SEQUENCE_LENGTH):\n",
    "            video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "            frame_found, frame = video_reader.read()\n",
    "            if not frame_found:\n",
    "                print(\"Error: Unable to read frame from video.\")\n",
    "                return\n",
    "            resized_frame = cv2.resize(frame, (VIDEO_FRAME_HEIGHT, VIDEO_FRAME_WIDTH))\n",
    "            normalized_frame = resized_frame / 255\n",
    "            frames_list.append(normalized_frame)\n",
    "        predicted_labels_probabilities = my_model.predict(np.expand_dims(frames_list, axis=0))[0]\n",
    "        predicted_label_index = np.argmax(predicted_labels_probabilities)\n",
    "        predicted_class_name = CLASS_LABELS[predicted_label_index]\n",
    "        prediction_confidence = predicted_labels_probabilities[predicted_label_index]\n",
    "        return (predicted_class_name, prediction_confidence)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        if video_reader:\n",
    "            video_reader.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T14:30:27.723821Z",
     "iopub.status.busy": "2023-11-13T14:30:27.723311Z",
     "iopub.status.idle": "2023-11-13T14:30:28.602794Z",
     "shell.execute_reply": "2023-11-13T14:30:28.601889Z",
     "shell.execute_reply.started": "2023-11-13T14:30:27.723783Z"
    },
    "id": "O6DQ5V-b3aUF",
    "outputId": "2509c4e5-de79-4431-d18f-7caf178b4d01",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_class = random.choice(CLASS_LABELS)\n",
    "path = os.path.join(DATASET_DIRECTORY, random_class)\n",
    "random_video = random.choice(os.listdir(path))\n",
    "\n",
    "# Specifying video to be predicted\n",
    "input_video_file_path = os.path.join(path, random_video)\n",
    "\n",
    "# Perform Single Prediction on the Test Video.\n",
    "predicted_class_name, prediction_confidence = predict_video_class(input_video_file_path, FRAMES_IN_SEQUENCE)\n",
    "\n",
    "# Output\n",
    "print(f'Predicted Class: {predicted_class_name}')\n",
    "print(f'Confidence: {prediction_confidence}')\n",
    "\n",
    "print(\"Prediction is\",predicted_class_name == random_class)\n",
    "\n",
    "print(f\"\\nFor Referene: Choosen Video = {random_video}\\nPath: \\'{input_video_file_path}\\'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 176381,
     "sourceId": 397693,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30260,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
